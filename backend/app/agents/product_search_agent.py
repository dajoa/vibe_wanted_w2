import os
import uuid
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.runnables import RunnableConfig
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph, MessagesState, START
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.store.base import BaseStore
from app.config import config


class ProductSearchAgent:
    """ìƒí’ˆ ê²€ìƒ‰ì„ ìœ„í•œ LangGraph React Agent"""
    
    def __init__(self):
        """Agent ì´ˆê¸°í™”"""
        # LangSmith ì„¤ì •
        config.configure_langsmith()
        
        # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.checkpointer = InMemorySaver()
        self.store = InMemoryStore()
        
        # ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì €ìž¥ì†Œ (thread_idë³„ë¡œ ê´€ë¦¬)
        self.conversation_history = {}
        
        # DuckDuckGo ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™” (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
        self.search_tool = DuckDuckGoSearchRun()
        
        # Google API í‚¤ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ëª…ì‹œì ìœ¼ë¡œ)
        self.llm = None
        self.agent = None
        self.graph = None
        self.use_agent = False
        
        if config.GOOGLE_API_KEY:
            os.environ["GOOGLE_API_KEY"] = config.GOOGLE_API_KEY
            # ì¶”ê°€ í™˜ê²½ ë³€ìˆ˜ë“¤ë„ ì„¤ì •
            os.environ["GOOGLE_GENAI_API_KEY"] = config.GOOGLE_API_KEY
            os.environ["GEMINI_API_KEY"] = config.GOOGLE_API_KEY
            
            try:
                # Gemini ëª¨ë¸ ì´ˆê¸°í™”
                self.llm = ChatGoogleGenerativeAI(
                    model="gemini-2.0-flash-exp",
                    google_api_key=config.GOOGLE_API_KEY,
                    temperature=0.1
                )
                
                # StateGraph ê¸°ë°˜ ë©”ëª¨ë¦¬ Agent ìƒì„±
                self._create_memory_agent()
                self.use_agent = True
                
            except Exception as e:
                print(f"Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # Agent ì—†ì´ ì§ì ‘ ê²€ìƒ‰ë§Œ ì‚¬ìš©
                self.use_agent = False
    
    def search_products(self, query: str) -> str:
        """
        ìƒí’ˆ ê²€ìƒ‰ ì‹¤í–‰
        
        Args:
            query: ê²€ìƒ‰í•  ìƒí’ˆëª… ë˜ëŠ” í‚¤ì›Œë“œ
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì‘ë‹µ ë¬¸ìžì—´
        """
        if not query.strip():
            return "ê²€ìƒ‰í•  ìƒí’ˆëª…ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”."
        
        # Graphë¥¼ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ê²½ìš°
        if self.use_agent and self.graph:
            try:
                # StateGraph ì‹¤í–‰ (ê¸°ë³¸ ì„¸ì…˜ìœ¼ë¡œ)
                config = {
                    "configurable": {
                        "thread_id": str(uuid.uuid4()),
                        "user_id": "default_user"
                    }
                }
                
                result = None
                for chunk in self.graph.stream(
                    {"messages": [{"role": "user", "content": query}]},
                    config,
                    stream_mode="values"
                ):
                    result = chunk
                
                # ë§ˆì§€ë§‰ ë©”ì‹œì§€ (AI ì‘ë‹µ) ë°˜í™˜
                if result and "messages" in result:
                    return result["messages"][-1].content
                else:
                    return "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    
            except Exception as e:
                print(f"Graph ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨ ì‹œ ì§ì ‘ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                return self._direct_search(query)
        else:
            # Graphë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì§ì ‘ ê²€ìƒ‰
            return self._direct_search(query)
    
    def _direct_search(self, query: str) -> str:
        """DuckDuckGo ì§ì ‘ ê²€ìƒ‰"""
        try:
            # DuckDuckGo ì§ì ‘ ê²€ìƒ‰
            search_results = self.search_tool.run(f"{query} ìƒí’ˆ ê°€ê²© ë¦¬ë·° êµ¬ë§¤")
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_result = f"""ðŸ” '{query}' ìƒí’ˆ ê²€ìƒ‰ ê²°ê³¼

{search_results}

ðŸ“ ì¶”ì²œì‚¬í•­:
â€¢ ì—¬ëŸ¬ ì‡¼í•‘ëª°ì—ì„œ ê°€ê²©ì„ ë¹„êµí•´ë³´ì„¸ìš”
â€¢ ì‚¬ìš©ìž ë¦¬ë·°ì™€ í‰ì ì„ í™•ì¸í•˜ì„¸ìš”  
â€¢ ë°°ì†¡ë¹„ì™€ ë°˜í’ˆ ì •ì±…ì„ í™•ì¸í•˜ì„¸ìš”
â€¢ ì •í’ˆ ì¸ì¦ê³¼ A/S ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”

â€» êµ¬ì²´ì ì¸ ê°€ê²©ê³¼ ìž¬ê³ ëŠ” ê° ì‡¼í•‘ëª°ì—ì„œ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”."""
            
            return formatted_result
            
        except Exception as e:
            return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _create_memory_agent(self):
        """ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ê°€ì§„ StateGraph Agent ìƒì„±"""
        def call_model(
            state: MessagesState,
            config: RunnableConfig,
            *,
            store: BaseStore,
        ):
            # ì‚¬ìš©ìž IDì™€ ìŠ¤ë ˆë“œ ID ì¶”ì¶œ
            user_id = config.get("configurable", {}).get("user_id", "default_user")
            thread_id = config.get("configurable", {}).get("thread_id", "default_thread")
            namespace = ("memories", user_id)
            
            # í˜„ìž¬ ë©”ì‹œì§€
            current_message = state["messages"][-1]
            
            # ê¸°ì¡´ ë©”ëª¨ë¦¬ ê²€ìƒ‰ (ì‚¬ìš©ìžë³„ ê´€ì‹¬ì‚¬)
            memories = store.search(namespace, query=str(current_message.content))
            memory_context = self.build_memory_context([m.value for m in memories])
            
            # ì´ì „ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            conversation_history = ""
            if len(state["messages"]) > 1:
                conversation_history = "\n## ì´ì „ ëŒ€í™” ë‚´ìš©:\n"
                for i, msg in enumerate(state["messages"][:-1]):  # í˜„ìž¬ ë©”ì‹œì§€ ì œì™¸
                    role = "ì‚¬ìš©ìž" if msg.type == "human" else "AI"
                    conversation_history += f"{i+1}. {role}: {msg.content}\n"
            
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë©”ëª¨ë¦¬ì™€ ëŒ€í™” ížˆìŠ¤í† ë¦¬ í¬í•¨
            system_prompt = f"""ë‹¹ì‹ ì€ ìƒí’ˆ ê°€ê²© ë¹„êµ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžê°€ ìš”ì²­í•œ ìƒí’ˆì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì €ê°€ ê°€ê²© ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

{memory_context}

{conversation_history}

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”:
- ìƒí’ˆëª…ê³¼ ë¸Œëžœë“œ
- ì£¼ìš” íŠ¹ì§• ë° ì‚¬ì–‘
- ê°€ê²© ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
- êµ¬ë§¤ ê°€ëŠ¥í•œ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°
- ì‚¬ìš©ìž ë¦¬ë·°ë‚˜ í‰ì  (ìžˆëŠ” ê²½ìš°)

**ì¤‘ìš”**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì—°ê´€ëœ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë§¥ë½ì„ ê³ ë ¤í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ì˜ˆë¥¼ ë“¤ì–´, ì´ì „ì— íŠ¹ì • ì œí’ˆì„ ì¶”ì²œí–ˆë‹¤ë©´ í›„ì† ì§ˆë¬¸ì—ì„œ ê·¸ ì œí’ˆë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ë©°, ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."""

            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            search_query = f"{current_message.content} ìƒí’ˆ ê°€ê²© ë¦¬ë·° êµ¬ë§¤"
            search_results = self.search_tool.run(search_query)
            
            # LLM ì‘ë‹µ ìƒì„±
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{current_message.content}'ì— ëŒ€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n{search_results}"}
            ]
            
            response = self.llm.invoke(messages)
            
            # ëª¨ë“  ëŒ€í™”ë¥¼ ë©”ëª¨ë¦¬ì— ì €ìž¥ (ê´€ì‹¬ì‚¬ ì¶”ì¶œ)
            memory_data = {
                "data": f"ì‚¬ìš©ìž ì§ˆë¬¸: {current_message.content}",
                "timestamp": str(uuid.uuid4()),
                "thread_id": thread_id
            }
            store.put(namespace, str(uuid.uuid4()), memory_data)
            
            # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìžˆìœ¼ë©´ ì¶”ê°€ ë©”ëª¨ë¦¬ ì €ìž¥
            product_keywords = ["ìŠ¤ë§ˆíŠ¸í°", "ë…¸íŠ¸ë¶", "íƒœë¸”ë¦¿", "ì´ì–´í°", "í—¤ë“œí°", "ì¹´ë©”ë¼", "TV", "ëª¨ë‹ˆí„°"]
            for keyword in product_keywords:
                if keyword in current_message.content:
                    product_memory = {
                        "data": f"ì‚¬ìš©ìžê°€ {keyword}ì— ê´€ì‹¬ì„ ë³´ìž„",
                        "product_type": keyword,
                        "thread_id": thread_id
                    }
                    store.put(namespace, str(uuid.uuid4()), product_memory)
                    break
            
            return {"messages": [response]}
        
        # StateGraph ìƒì„±
        builder = StateGraph(MessagesState)
        builder.add_node("call_model", call_model)
        builder.add_edge(START, "call_model")
        
        # ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œê³¼ í•¨ê»˜ ì»´íŒŒì¼ (checkpointerë¡œ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ì €ìž¥)
        self.graph = builder.compile(
            checkpointer=self.checkpointer,
            store=self.store
        )
    
    def add_to_conversation_history(self, thread_id: str, user_message: str, ai_response: str):
        """ëŒ€í™” ížˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        if thread_id not in self.conversation_history:
            self.conversation_history[thread_id] = []
        
        self.conversation_history[thread_id].append({
            "user": user_message,
            "ai": ai_response,
            "timestamp": str(uuid.uuid4())
        })
    
    def get_conversation_history(self, thread_id: str) -> str:
        """ëŒ€í™” ížˆìŠ¤í† ë¦¬ë¥¼ ë¬¸ìžì—´ë¡œ ë°˜í™˜"""
        if thread_id not in self.conversation_history or not self.conversation_history[thread_id]:
            return ""
        
        history_text = "\n## ì´ì „ ëŒ€í™” ë‚´ìš©:\n"
        for i, conv in enumerate(self.conversation_history[thread_id]):
            history_text += f"{i+1}. ì‚¬ìš©ìž: {conv['user']}\n"
            history_text += f"{i+1}. AI: {conv['ai']}\n\n"
        
        return history_text
    
    def search_products_with_memory(self, query: str, thread_id: str = None, user_id: str = None) -> str:
        """
        ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ í¬í•¨í•œ ìƒí’ˆ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰í•  ìƒí’ˆëª… ë˜ëŠ” í‚¤ì›Œë“œ
            thread_id: ëŒ€í™” ì„¸ì…˜ ID
            user_id: ì‚¬ìš©ìž ID
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì‘ë‹µ ë¬¸ìžì—´
        """
        if not query.strip():
            return "ê²€ìƒ‰í•  ìƒí’ˆëª…ì„ ìž…ë ¥í•´ì£¼ì„¸ìš”."
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not thread_id:
            thread_id = str(uuid.uuid4())
        if not user_id:
            user_id = "default_user"
        
        # ì´ì „ ëŒ€í™” ížˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
        conversation_history = self.get_conversation_history(thread_id)
        
        # ì‚¬ìš©ìžë³„ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        namespace = ("memories", user_id)
        memories = self.store.search(namespace, query=query)
        memory_context = self.build_memory_context([m.value for m in memories])
        
        # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
        search_query = f"{query} ìƒí’ˆ ê°€ê²© ë¦¬ë·° êµ¬ë§¤"
        search_results = self.search_tool.run(search_query)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""ë‹¹ì‹ ì€ ìƒí’ˆ ê°€ê²© ë¹„êµ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.
ì‚¬ìš©ìžê°€ ìš”ì²­í•œ ìƒí’ˆì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í†µí•´ ìµœì €ê°€ ê°€ê²© ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

{memory_context}

{conversation_history}

**ì¤‘ìš”**: ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì—¬ ì—°ê´€ëœ ì§ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë§¥ë½ì„ ê³ ë ¤í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.
ì˜ˆë¥¼ ë“¤ì–´, ì´ì „ì— "ê°¤ëŸ­ì‹œ ìŠ¤ë§ˆíŠ¸í°"ì„ ì¶”ì²œí–ˆë‹¤ë©´, "ê·¸ ì¤‘ì—ì„œ 50ë§Œì› ì´í•˜ì¸ ê²ƒ"ì´ë¼ëŠ” í›„ì† ì§ˆë¬¸ì—ì„œëŠ” 
ê°¤ëŸ­ì‹œ ìŠ¤ë§ˆíŠ¸í° ì¤‘ì—ì„œ 50ë§Œì› ì´í•˜ì¸ ëª¨ë¸ë“¤ì„ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”:
- ìƒí’ˆëª…ê³¼ ë¸Œëžœë“œ
- ì£¼ìš” íŠ¹ì§• ë° ì‚¬ì–‘
- ê°€ê²© ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
- êµ¬ë§¤ ê°€ëŠ¥í•œ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°
- ì‚¬ìš©ìž ë¦¬ë·°ë‚˜ í‰ì  (ìžˆëŠ” ê²½ìš°)

í•­ìƒ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ë©°, ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”."""

        try:
            # LLMì„ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ê²½ìš°
            if self.use_agent and self.llm:
                # ì‚¬ìš©ìž ë©”ì‹œì§€ì— ë§¥ë½ ì •ë³´ í¬í•¨
                user_message = f"í˜„ìž¬ ì§ˆë¬¸: '{query}'\n\n"
                
                # ì´ì „ ëŒ€í™”ê°€ ìžˆë‹¤ë©´ ë§¥ë½ ížŒíŠ¸ ì¶”ê°€
                if conversation_history:
                    user_message += "**ì¤‘ìš”**: ìœ„ì˜ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, í˜„ìž¬ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™”ì™€ ì—°ê´€ëœ í›„ì† ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ê³  ë§¥ë½ì„ ê³ ë ¤í•´ì„œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n"
                
                user_message += f"ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n{search_results}"
                
                # LLM ì‘ë‹µ ìƒì„±
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
                
                response = self.llm.invoke(messages)
                ai_response = response.content
                
                # ëŒ€í™” ížˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                self.add_to_conversation_history(thread_id, query, ai_response)
                
                # ì‚¬ìš©ìž ë©”ëª¨ë¦¬ì— ì €ìž¥
                memory_data = {
                    "data": f"ì‚¬ìš©ìž ì§ˆë¬¸: {query}",
                    "thread_id": thread_id
                }
                self.store.put(namespace, str(uuid.uuid4()), memory_data)
                
                # ìƒí’ˆ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìžˆìœ¼ë©´ ì¶”ê°€ ë©”ëª¨ë¦¬ ì €ìž¥
                product_keywords = ["ìŠ¤ë§ˆíŠ¸í°", "ê°¤ëŸ­ì‹œ", "ì•„ì´í°", "ë…¸íŠ¸ë¶", "íƒœë¸”ë¦¿", "ì´ì–´í°", "í—¤ë“œí°", "ì¹´ë©”ë¼", "TV", "ëª¨ë‹ˆí„°"]
                for keyword in product_keywords:
                    if keyword in query:
                        product_memory = {
                            "data": f"ì‚¬ìš©ìžê°€ {keyword}ì— ê´€ì‹¬ì„ ë³´ìž„",
                            "product_type": keyword,
                            "thread_id": thread_id
                        }
                        self.store.put(namespace, str(uuid.uuid4()), product_memory)
                        break
                
                return ai_response
                
            else:
                # LLMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ê²€ìƒ‰
                result = self._direct_search(query)
                self.add_to_conversation_history(thread_id, query, result)
                return result
                
        except Exception as e:
            print(f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
            result = self._direct_search(query)
            self.add_to_conversation_history(thread_id, query, result)
            return result
    
    def store_user_memory(self, user_id: str, memory_key: str, memory_data: dict):
        """ì‚¬ìš©ìž ë©”ëª¨ë¦¬ ì €ìž¥"""
        namespace = ("memories", user_id)
        memory_id = str(uuid.uuid4())
        self.store.put(namespace, memory_id, memory_data)
    
    def get_user_memories(self, user_id: str) -> list:
        """ì‚¬ìš©ìž ë©”ëª¨ë¦¬ ì¡°íšŒ"""
        namespace = ("memories", user_id)
        memories = self.store.search(namespace)
        return [memory.value for memory in memories]
    
    def build_memory_context(self, memories: list) -> str:
        """ë©”ëª¨ë¦¬ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´ë¡œ ë³€í™˜"""
        if not memories:
            return ""
        
        context_parts = ["## ì‚¬ìš©ìž ì •ë³´ ë° ì´ì „ ëŒ€í™” ë‚´ìš©:"]
        for memory in memories:
            if isinstance(memory, dict) and "data" in memory:
                context_parts.append(f"- {memory['data']}")
        
        return "\n".join(context_parts) if len(context_parts) > 1 else ""